{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed94ce2",
   "metadata": {
    "papermill": {
     "duration": 0.004013,
     "end_time": "2025-02-28T07:12:00.273879",
     "exception": false,
     "start_time": "2025-02-28T07:12:00.269866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "Here we are using emsemble models to help us predict who out of a list of passengers would be \"Transported\".\n",
    "\n",
    "Thank you to Nikhil R for his workbook, [here](https://www.kaggle.com/code/nikhilramlukan/spaceship-titanic/notebook). Which was the inspiration for my approach below.\n",
    "\n",
    "I took it one step further by doing Hyperparameter Tuning, Kfold cross validation. And having 2 models at the second layer to work with the predictions of the base layer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ace35b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:12:00.282945Z",
     "iopub.status.busy": "2025-02-28T07:12:00.282575Z",
     "iopub.status.idle": "2025-02-28T07:12:05.308080Z",
     "shell.execute_reply": "2025-02-28T07:12:05.306554Z"
    },
    "papermill": {
     "duration": 5.034022,
     "end_time": "2025-02-28T07:12:05.311822",
     "exception": false,
     "start_time": "2025-02-28T07:12:00.277800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf10c1",
   "metadata": {
    "papermill": {
     "duration": 0.003306,
     "end_time": "2025-02-28T07:12:05.319027",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.315721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9446327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:12:05.328006Z",
     "iopub.status.busy": "2025-02-28T07:12:05.327488Z",
     "iopub.status.idle": "2025-02-28T07:12:05.333756Z",
     "shell.execute_reply": "2025-02-28T07:12:05.332330Z"
    },
    "papermill": {
     "duration": 0.013425,
     "end_time": "2025-02-28T07:12:05.336065",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.322640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    train_res = train['Transported'].astype(int)\n",
    "    test_id = test['PassengerId']\n",
    "    return train, test, train_res, test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d40d9",
   "metadata": {
    "papermill": {
     "duration": 0.003545,
     "end_time": "2025-02-28T07:12:05.343172",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.339627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10277a01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:12:05.352960Z",
     "iopub.status.busy": "2025-02-28T07:12:05.352190Z",
     "iopub.status.idle": "2025-02-28T07:12:05.366468Z",
     "shell.execute_reply": "2025-02-28T07:12:05.364626Z"
    },
    "papermill": {
     "duration": 0.022159,
     "end_time": "2025-02-28T07:12:05.369471",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.347312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train, test):\n",
    "    mappings = {\"Europa\": 1, \"Earth\": 2, \"Mars\": 3}\n",
    "    train['HomePlanet'] = train['HomePlanet'].map(mappings).fillna(0)\n",
    "    test['HomePlanet'] = test['HomePlanet'].map(mappings).fillna(0)\n",
    "    \n",
    "    train[['Cabin_1', 'Cabin_2', 'Cabin_3']] = train['Cabin'].str.split('/', expand=True)\n",
    "    test[['Cabin_1', 'Cabin_2', 'Cabin_3']] = test['Cabin'].str.split('/', expand=True)\n",
    "    \n",
    "    cabin_1_mapping = {\"B\": 1, \"F\": 2, \"A\": 3, \"G\": 4, \"E\": 5, \"D\": 6, \"C\": 7, \"T\": 8}\n",
    "    train['Cabin_1'] = train['Cabin_1'].map(cabin_1_mapping).fillna(0)\n",
    "    test['Cabin_1'] = test['Cabin_1'].map(cabin_1_mapping).fillna(0)\n",
    "    \n",
    "    cabin_3_mapping = {\"P\": 1, \"S\": 2}\n",
    "    train['Cabin_3'] = train['Cabin_3'].map(cabin_3_mapping).fillna(0)\n",
    "    test['Cabin_3'] = test['Cabin_3'].map(cabin_3_mapping).fillna(0)\n",
    "    \n",
    "    cols = ['FoodCourt', 'RoomService', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    for col in cols:\n",
    "        train[col] = train[col].fillna(train[col].median())\n",
    "        test[col] = test[col].fillna(test[col].median())\n",
    "\n",
    "    # Convert categorical columns to 'category' dtype\n",
    "    categorical_columns = ['CryoSleep', 'VIP']\n",
    "    for col in categorical_columns:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "\n",
    "        # Add 'Missing' category if it's not already present\n",
    "        if 'Missing' not in train[col].cat.categories:\n",
    "            train[col] = train[col].cat.add_categories('Missing')\n",
    "        if 'Missing' not in test[col].cat.categories:\n",
    "            test[col] = test[col].cat.add_categories('Missing')\n",
    "\n",
    "        # Now, fill NaN values with 'Missing'\n",
    "        train[col] = train[col].fillna('Missing')\n",
    "        test[col] = test[col].fillna('Missing')\n",
    "\n",
    "    # Advanced Feature Engineering\n",
    "    train['FamilySize'] = train['PassengerId'].apply(lambda x: int(x.split('_')[0]))\n",
    "    test['FamilySize'] = test['PassengerId'].apply(lambda x: int(x.split('_')[0]))\n",
    "    \n",
    "    train['Spending'] = train[cols].sum(axis=1)\n",
    "    test['Spending'] = test[cols].sum(axis=1)\n",
    "    \n",
    "    train['MissingValues'] = train.isnull().sum(axis=1)\n",
    "    test['MissingValues'] = test.isnull().sum(axis=1)\n",
    "    \n",
    "    train.drop(['Name', 'Transported', 'PassengerId', 'Cabin', 'Cabin_2', 'Destination'], axis=1, inplace=True)\n",
    "    test.drop(['Name', 'PassengerId', 'Cabin', 'Cabin_2', 'Destination'], axis=1, inplace=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f3db60",
   "metadata": {
    "papermill": {
     "duration": 0.003479,
     "end_time": "2025-02-28T07:12:05.377387",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.373908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbab419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:12:05.387979Z",
     "iopub.status.busy": "2025-02-28T07:12:05.387033Z",
     "iopub.status.idle": "2025-02-28T07:12:05.395322Z",
     "shell.execute_reply": "2025-02-28T07:12:05.393942Z"
    },
    "papermill": {
     "duration": 0.016464,
     "end_time": "2025-02-28T07:12:05.397532",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.381068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tune_xgb(train, train_res):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1],\n",
    "        'colsample_bytree': [0.8, 1]\n",
    "    }\n",
    "    xgb = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, random_state=42, enable_categorical=True)\n",
    "    grid_search = GridSearchCV(xgb, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(train, train_res)\n",
    "    print(\"Best parameters for XGBoost:\", grid_search.best_params_)\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd87e67",
   "metadata": {
    "papermill": {
     "duration": 0.003482,
     "end_time": "2025-02-28T07:12:05.404697",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.401215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa60688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:12:05.413619Z",
     "iopub.status.busy": "2025-02-28T07:12:05.413177Z",
     "iopub.status.idle": "2025-02-28T07:12:05.421337Z",
     "shell.execute_reply": "2025-02-28T07:12:05.420268Z"
    },
    "papermill": {
     "duration": 0.015293,
     "end_time": "2025-02-28T07:12:05.423718",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.408425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_base_models(train, train_res):\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    models = {\n",
    "        \"XGB\": tune_xgb(train, train_res),\n",
    "        \"LGB\": LGBMClassifier(random_state=42),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
    "    }\n",
    "    oof_preds = np.zeros((train.shape[0], len(models)))\n",
    "    \n",
    "    # List of categorical columns\n",
    "    cat_features = ['CryoSleep', 'VIP']\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train, train_res)):\n",
    "        X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "        y_train, y_val = train_res.iloc[train_idx], train_res.iloc[val_idx]\n",
    "        \n",
    "        for i, (name, model) in enumerate(models.items()):\n",
    "            if name == \"CatBoost\":\n",
    "                model.fit(X_train, y_train, cat_features=cat_features)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            oof_preds[val_idx, i] = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    return models, oof_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d45400",
   "metadata": {
    "papermill": {
     "duration": 0.0033,
     "end_time": "2025-02-28T07:12:05.430696",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.427396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Meta Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f40218",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:12:05.439351Z",
     "iopub.status.busy": "2025-02-28T07:12:05.438969Z",
     "iopub.status.idle": "2025-02-28T07:12:05.445465Z",
     "shell.execute_reply": "2025-02-28T07:12:05.444429Z"
    },
    "papermill": {
     "duration": 0.013142,
     "end_time": "2025-02-28T07:12:05.447537",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.434395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_meta_models(oof_preds, train_res):\n",
    "    oof_preds_df = pd.DataFrame(oof_preds, columns=[\"XGB\", \"LGB\", \"CatBoost\"])\n",
    "    meta_models = {\n",
    "        \"LogisticRegression\": LogisticRegression(),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    meta_model_scores = {}\n",
    "    for name, model in meta_models.items():\n",
    "        scores = cross_val_score(model, oof_preds_df, train_res, cv=5, scoring='accuracy')\n",
    "        meta_model_scores[name] = scores.mean()\n",
    "        print(f\"{name} CV Accuracy: {scores.mean():.4f}\")\n",
    "    \n",
    "    best_meta_model = max(meta_model_scores, key=meta_model_scores.get)\n",
    "    meta_models[best_meta_model].fit(oof_preds_df, train_res)\n",
    "    \n",
    "    return meta_models, best_meta_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0af27b",
   "metadata": {
    "papermill": {
     "duration": 0.003159,
     "end_time": "2025-02-28T07:12:05.454240",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.451081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f809c5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:12:05.462480Z",
     "iopub.status.busy": "2025-02-28T07:12:05.462101Z",
     "iopub.status.idle": "2025-02-28T07:12:05.468518Z",
     "shell.execute_reply": "2025-02-28T07:12:05.467260Z"
    },
    "papermill": {
     "duration": 0.013069,
     "end_time": "2025-02-28T07:12:05.470570",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.457501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(models, meta_models, best_meta_model, test, test_id):\n",
    "    test_preds = np.column_stack([\n",
    "        models[name].predict_proba(test)[:, 1] for name in models.keys()\n",
    "    ])\n",
    "    final_preds = meta_models[best_meta_model].predict(test_preds)\n",
    "    \n",
    "    submission = pd.DataFrame({'PassengerId': test_id, 'Transported': final_preds.astype(bool)})\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3bfc51",
   "metadata": {
    "papermill": {
     "duration": 0.003405,
     "end_time": "2025-02-28T07:12:05.478468",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.475063",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2c8f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T07:12:05.487412Z",
     "iopub.status.busy": "2025-02-28T07:12:05.486464Z",
     "iopub.status.idle": "2025-02-28T07:13:45.027211Z",
     "shell.execute_reply": "2025-02-28T07:13:45.024658Z"
    },
    "papermill": {
     "duration": 99.547964,
     "end_time": "2025-02-28T07:13:45.029855",
     "exception": false,
     "start_time": "2025-02-28T07:12:05.481891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best parameters for XGBoost: {'colsample_bytree': 1, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1893\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1893\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1894\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1893\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "LogisticRegression CV Accuracy: 0.8101\n",
      "RandomForest CV Accuracy: 0.7860\n",
      "Submission file saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, test, train_res, test_id = load_data(\"/kaggle/input/spaceship-titanic/train.csv\", \"/kaggle/input/spaceship-titanic/test.csv\")\n",
    "train, test = preprocess_data(train, test)\n",
    "models, oof_preds = train_base_models(train, train_res)\n",
    "meta_models, best_meta_model = train_meta_models(oof_preds, train_res)\n",
    "predict(models, meta_models, best_meta_model, test, test_id)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 110.787529,
   "end_time": "2025-02-28T07:13:47.663674",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-28T07:11:56.876145",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
